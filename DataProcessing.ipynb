{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GL6DeV4r5POO",
    "outputId": "11844b6f-ecd6-456b-f977-405e327c6ef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-text in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (2.9.0)\n",
      "Requirement already satisfied: tensorflow-macos<2.10,>=2.9.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorflow-text) (2.9.2)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorflow-text) (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorflow-hub>=0.8.0->tensorflow-text) (1.22.4)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorflow-hub>=0.8.0->tensorflow-text) (3.19.4)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (3.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (1.1.2)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (0.4.0)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (4.2.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (1.12)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (2.9.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (1.14.1)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (2.9.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (2.9.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (14.0.1)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (62.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (1.47.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (2.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (2.1.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (2.28.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from packaging->tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (3.0.9)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (4.12.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (2.0.12)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-macos<2.10,>=2.9.0->tensorflow-text) (3.2.0)\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J7oBVr-EM-5e",
    "outputId": "26c1cba7-1ecd-4a8a-9d8e-32da23b291bc"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages/pandas/__init__.py:48\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     Int8Dtype,\n\u001b[1;32m     51\u001b[0m     Int16Dtype,\n\u001b[1;32m     52\u001b[0m     Int32Dtype,\n\u001b[1;32m     53\u001b[0m     Int64Dtype,\n\u001b[1;32m     54\u001b[0m     UInt8Dtype,\n\u001b[1;32m     55\u001b[0m     UInt16Dtype,\n\u001b[1;32m     56\u001b[0m     UInt32Dtype,\n\u001b[1;32m     57\u001b[0m     UInt64Dtype,\n\u001b[1;32m     58\u001b[0m     Float32Dtype,\n\u001b[1;32m     59\u001b[0m     Float64Dtype,\n\u001b[1;32m     60\u001b[0m     CategoricalDtype,\n\u001b[1;32m     61\u001b[0m     PeriodDtype,\n\u001b[1;32m     62\u001b[0m     IntervalDtype,\n\u001b[1;32m     63\u001b[0m     DatetimeTZDtype,\n\u001b[1;32m     64\u001b[0m     StringDtype,\n\u001b[1;32m     65\u001b[0m     BooleanDtype,\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     NA,\n\u001b[1;32m     68\u001b[0m     isna,\n\u001b[1;32m     69\u001b[0m     isnull,\n\u001b[1;32m     70\u001b[0m     notna,\n\u001b[1;32m     71\u001b[0m     notnull,\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     Index,\n\u001b[1;32m     74\u001b[0m     CategoricalIndex,\n\u001b[1;32m     75\u001b[0m     RangeIndex,\n\u001b[1;32m     76\u001b[0m     MultiIndex,\n\u001b[1;32m     77\u001b[0m     IntervalIndex,\n\u001b[1;32m     78\u001b[0m     TimedeltaIndex,\n\u001b[1;32m     79\u001b[0m     DatetimeIndex,\n\u001b[1;32m     80\u001b[0m     PeriodIndex,\n\u001b[1;32m     81\u001b[0m     IndexSlice,\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     NaT,\n\u001b[1;32m     84\u001b[0m     Period,\n\u001b[1;32m     85\u001b[0m     period_range,\n\u001b[1;32m     86\u001b[0m     Timedelta,\n\u001b[1;32m     87\u001b[0m     timedelta_range,\n\u001b[1;32m     88\u001b[0m     Timestamp,\n\u001b[1;32m     89\u001b[0m     date_range,\n\u001b[1;32m     90\u001b[0m     bdate_range,\n\u001b[1;32m     91\u001b[0m     Interval,\n\u001b[1;32m     92\u001b[0m     interval_range,\n\u001b[1;32m     93\u001b[0m     DateOffset,\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     to_numeric,\n\u001b[1;32m     96\u001b[0m     to_datetime,\n\u001b[1;32m     97\u001b[0m     to_timedelta,\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     Flags,\n\u001b[1;32m    100\u001b[0m     Grouper,\n\u001b[1;32m    101\u001b[0m     factorize,\n\u001b[1;32m    102\u001b[0m     unique,\n\u001b[1;32m    103\u001b[0m     value_counts,\n\u001b[1;32m    104\u001b[0m     NamedAgg,\n\u001b[1;32m    105\u001b[0m     array,\n\u001b[1;32m    106\u001b[0m     Categorical,\n\u001b[1;32m    107\u001b[0m     set_eng_float_format,\n\u001b[1;32m    108\u001b[0m     Series,\n\u001b[1;32m    109\u001b[0m     DataFrame,\n\u001b[1;32m    110\u001b[0m )\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages/pandas/core/api.py:29\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     isna,\n\u001b[1;32m     19\u001b[0m     isnull,\n\u001b[1;32m     20\u001b[0m     notna,\n\u001b[1;32m     21\u001b[0m     notnull,\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     factorize,\n\u001b[1;32m     26\u001b[0m     unique,\n\u001b[1;32m     27\u001b[0m     value_counts,\n\u001b[1;32m     28\u001b[0m )\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Categorical\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mboolean\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BooleanDtype\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfloating\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     Float32Dtype,\n\u001b[1;32m     33\u001b[0m     Float64Dtype,\n\u001b[1;32m     34\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages/pandas/core/arrays/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     ExtensionArray,\n\u001b[1;32m      3\u001b[0m     ExtensionOpsMixin,\n\u001b[1;32m      4\u001b[0m     ExtensionScalarOpsMixin,\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mboolean\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BooleanArray\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcategorical\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Categorical\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages/pandas/core/arrays/base.py:68\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     62\u001b[0m     ABCDataFrame,\n\u001b[1;32m     63\u001b[0m     ABCIndex,\n\u001b[1;32m     64\u001b[0m     ABCSeries,\n\u001b[1;32m     65\u001b[0m )\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m isna\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     69\u001b[0m     arraylike,\n\u001b[1;32m     70\u001b[0m     missing,\n\u001b[1;32m     71\u001b[0m     roperator,\n\u001b[1;32m     72\u001b[0m )\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     74\u001b[0m     factorize_array,\n\u001b[1;32m     75\u001b[0m     isin,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m     unique,\n\u001b[1;32m     79\u001b[0m )\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray_algos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quantile_with_mask\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages/pandas/core/arraylike.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roperator\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstruction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extract_array\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unpack_zerodim_and_defer\n\u001b[1;32m     23\u001b[0m REDUCTION_ALIASES \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximum\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimum\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiply\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprod\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m }\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mOpsMixin\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# -------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Comparisons\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages/pandas/core/ops/__init__.py:33\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m isna\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     30\u001b[0m     algorithms,\n\u001b[1;32m     31\u001b[0m     roperator,\n\u001b[1;32m     32\u001b[0m )\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     arithmetic_op,\n\u001b[1;32m     35\u001b[0m     comp_method_OBJECT_ARRAY,\n\u001b[1;32m     36\u001b[0m     comparison_op,\n\u001b[1;32m     37\u001b[0m     get_array_op,\n\u001b[1;32m     38\u001b[0m     logical_op,\n\u001b[1;32m     39\u001b[0m     maybe_prepare_scalar_for_op,\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     get_op_result_name,\n\u001b[1;32m     43\u001b[0m     unpack_zerodim_and_defer,\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocstrings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     46\u001b[0m     _flex_comp_doc_FRAME,\n\u001b[1;32m     47\u001b[0m     _op_descriptions,\n\u001b[1;32m     48\u001b[0m     make_flex_doc,\n\u001b[1;32m     49\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tfenv/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:48\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     39\u001b[0m     ABCExtensionArray,\n\u001b[1;32m     40\u001b[0m     ABCIndex,\n\u001b[1;32m     41\u001b[0m     ABCSeries,\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     44\u001b[0m     isna,\n\u001b[1;32m     45\u001b[0m     notna,\n\u001b[1;32m     46\u001b[0m )\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomputation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpressions\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mexpressions\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstruction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ensure_wrapped_if_datetimelike\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     51\u001b[0m     missing,\n\u001b[1;32m     52\u001b[0m     roperator,\n\u001b[1;32m     53\u001b[0m )\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:157\u001b[0m, in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:196\u001b[0m, in \u001b[0;36m_get_module_lock\u001b[0;34m(name)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim\n",
    "nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "szMRmLV3W4-D"
   },
   "outputs": [],
   "source": [
    "!wget -c https://firebasestorage.googleapis.com/v0/b/william-personal-firebase.appspot.com/o/chatbot.zip?alt=media&token=f30ea369-1ffc-4163-baef-45b2e2f883c6 \n",
    "!unzip /content/chatbot.zip?alt=media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "itHjBy5OYT1o",
    "outputId": "d5d0d663-0b82-47d6-bf2b-f84ba176e817"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('content/archive/20000-Utterances-Training-dataset-for-chatbots-virtual-assistant-Bitext-sample/20000-Utterances-Training-dataset-for-chatbots-virtual-assistant-Bitext-sample/20000-Utterances-Training-dataset-for-chatbots-virtual-assistant-Bitext-sample.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bh3x4D98zaqx"
   },
   "source": [
    "Basic processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BNUHEwuSYkzc",
    "outputId": "1e96087b-9b47-4c0e-f248-1a8c930de4fd"
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "english_stopwords = stopwords.words('english')\n",
    "\n",
    "# lower case, tokenize, stopword, puctuation and stemming\n",
    "df['words'] = df['utterance'].str.lower()\n",
    "df['words'] = df['words'].apply(word_tokenize)\n",
    "df['words'] = df['words'].apply(lambda l: [porter.stem(word) for word in l if (word not in english_stopwords) and word.isalpha()])\n",
    "print(df['words'].head())\n",
    "print(df['words'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "JnMBkglLaUaW",
    "outputId": "37ff0d02-787d-4c06-f411-c23230666e29"
   },
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "fdist = FreqDist(df['words'].sum())\n",
    "fdist.most_common(3)\n",
    "fdist.plot(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dt3G3_EczXFW"
   },
   "source": [
    "Train test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TdnpgRESllkn"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state = 1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d35ueCvvzd2C"
   },
   "source": [
    "Count vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2OSqsH3Eceb5"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# merged words list\n",
    "train_words=[' '.join(text) for text in df_train['words']]\n",
    "test_words=[' '.join(text) for text in df_test['words']]\n",
    "\n",
    "# count\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_counts = count_vectorizer.fit_transform(train_words).toarray()\n",
    "X_test_counts = count_vectorizer.transform(test_words).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJQuLYtGzknm"
   },
   "source": [
    "Ngram vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AklgAf2RbGfa"
   },
   "outputs": [],
   "source": [
    "# ngram\n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "X_train_ng = ngram_vectorizer.fit_transform(train_words).toarray()\n",
    "X_test_ng = ngram_vectorizer.transform(test_words).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KgFKctLubHe-"
   },
   "outputs": [],
   "source": [
    "# tfidf\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "transformer = TfidfTransformer(smooth_idf=False);\n",
    "X_train_tfidf = transformer.fit_transform(X_train_counts);\n",
    "X_test_tfidf = transformer.transform(X_test_counts);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "id": "Rkwoyav8z_s2",
    "outputId": "a8f05626-ed69-4793-8bc0-a6529edf010c"
   },
   "outputs": [],
   "source": [
    "# pretrained word2vec\n",
    "import gensim.downloader as api\n",
    "wv_pretrain = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q8OGheTHZ0n4"
   },
   "outputs": [],
   "source": [
    "# custom word2vec\n",
    "import gensim\n",
    "model_w2v = gensim.models.Word2Vec(sentences=df_train['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wWD6YgoK90yr",
    "outputId": "5d3ad2b7-d441-4036-bfef-c4e84d0d869c"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/allenai/spv2/raw/master/model/glove.6B.100d.txt.gz\n",
    "!gzip -d -f glove.6B.100d.txt.gz\n",
    "!mv glove.6B.100d.txt content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FhOpR05l9zr0"
   },
   "outputs": [],
   "source": [
    "# pretrained glove\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_file = 'content/glove.6B.100d.txt'\n",
    "tmp_file = \"content/glove_100d_word2vec.txt\"\n",
    "\n",
    "_ = glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "glove_model = KeyedVectors.load_word2vec_format(tmp_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TIhqp359z7lp"
   },
   "outputs": [],
   "source": [
    "# pretrained bert\n",
    "from tensorflow.keras.layers import Input, Dropout\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text # just needed tensorflow_text\n",
    "\n",
    "bert_encoder_dir = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1'\n",
    "bert_preprocess_dir = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
    "\n",
    "bert_preprocess_layer = hub.KerasLayer(bert_preprocess_dir)\n",
    "bert_encode_model = hub.KerasLayer(bert_encoder_dir, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtUxCCXw_Cfw"
   },
   "outputs": [],
   "source": [
    "# tokenized seq for keras\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_train['words'])\n",
    "encoded_train_docs = tokenizer.texts_to_sequences(df_train['words'])\n",
    "encoded_test_docs = tokenizer.texts_to_sequences(df_test['words'])\n",
    "max_length = max([len(s) for s in df_train['words']])\n",
    "X_train = pad_sequences(encoded_train_docs, \n",
    "                        maxlen=max_length, \n",
    "                        padding='post')\n",
    "y_train = pd.get_dummies(df_train['category'])\n",
    "X_test = pad_sequences(encoded_test_docs, \n",
    "                        maxlen=max_length, \n",
    "                        padding='post')\n",
    "y_test = pd.get_dummies(df_test['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZsxm43s0FVE"
   },
   "source": [
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 732
    },
    "id": "9_6t3HxTtRE6",
    "outputId": "d2d73385-3de1-465c-e8da-bb96a4bef80b"
   },
   "outputs": [],
   "source": [
    "# plsa using tfidf train data\n",
    "\n",
    "from sklearn.decomposition import NMF;\n",
    "from sklearn.preprocessing import normalize;\n",
    "\n",
    "def get_nmf_topics(model, n_top_words):\n",
    "    \n",
    "    #the word ids obtained need to be reverse-mapped to the words so we can print the topic names.\n",
    "    feat_names = count_vectorizer.get_feature_names()\n",
    "    \n",
    "    word_dict = {};\n",
    "    for i in range(num_topics):\n",
    "        \n",
    "        #for each topic, obtain the largest values, and add the words they map to into the dictionary.\n",
    "        words_ids = model.components_[i].argsort()[:-n_top_words - 1:-1]\n",
    "        words = [feat_names[key] for key in words_ids]\n",
    "        word_dict['Topic # ' + '{:02d}'.format(i+1)] = words;\n",
    "    \n",
    "    return pd.DataFrame(word_dict)\n",
    "\n",
    "xtfidf_norm = normalize(X_train_tfidf, norm='l1', axis=1)\n",
    "num_topics=10\n",
    "plsa_model = NMF(n_components=num_topics, init='nndsvd');\n",
    "plsa_model.fit(xtfidf_norm)\n",
    "get_nmf_topics(plsa_model, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2VzwLfkxtzOR",
    "outputId": "0ea1fc30-04d4-4db1-dd62-07cd6126018e"
   },
   "outputs": [],
   "source": [
    "# word2vec + cnn\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Embedding, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "def get_word2vec_embed_layer(max_length, tokenizer, wv):\n",
    "    word_index = tokenizer.word_index\n",
    "    embedding_mat = np.zeros((len(word_index)+1, 100))\n",
    "    for word, i in word_index.items():\n",
    "        try:\n",
    "            vector = wv[word]\n",
    "            embedding_mat[i] = vector\n",
    "        except:\n",
    "            continue\n",
    "    word2vec_embedding_layer = Embedding(input_dim=embedding_mat.shape[0],\n",
    "                          output_dim=embedding_mat.shape[1], \n",
    "                          weights=[embedding_mat],\n",
    "                          input_length=max_length, \n",
    "                          trainable=False)\n",
    "    return word2vec_embedding_layer\n",
    "\n",
    "model_word2vec = Sequential()\n",
    "model_word2vec.add(get_word2vec_embed_layer(max_length, tokenizer, model_w2v.wv)) # use wv_pretrain instead of model_w2v.wv for pretrain w2v\n",
    "model_word2vec.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "model_word2vec.add(MaxPooling1D(pool_size=2))\n",
    "model_word2vec.add(Flatten())\n",
    "model_word2vec.add(Dense(11, activation='softmax'))\n",
    "print(model_word2vec.summary())\n",
    "model_word2vec.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_word2vec.fit(X_train, y_train, epochs=10)\n",
    "model_word2vec.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "Vd2pWvuoxuzM",
    "outputId": "e4732faf-5ff8-48c1-c22f-47ffdcc5bbed"
   },
   "outputs": [],
   "source": [
    "# bert + cnn\n",
    "from tensorflow.keras.layers import Input, Dropout\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "text_input = Input(shape=(), dtype=tf.string)\n",
    "bert_inputs = bert_preprocess_layer(text_input)\n",
    "outputs = bert_encode_model(bert_inputs)\n",
    "net = outputs['pooled_output']\n",
    "net = Dropout(0.1)(net)\n",
    "net = Dense(11, activation='softmax')(net)\n",
    "bert_model = Model(text_input, net)\n",
    "bert_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "bert_model.fit(tf.constant(train_words), y_train, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQ0uJ_JrzQi3",
    "outputId": "736c3e40-0020-44c7-d559-49f0426e7943"
   },
   "outputs": [],
   "source": [
    "# pretrained glove\n",
    "\n",
    "def get_glove_embed_layer(max_length, tokenizer, wv):\n",
    "    word_index = tokenizer.word_index\n",
    "    embedding_glove_mat = np.zeros((len(word_index)+1, 100))\n",
    "    for word, i in word_index.items():\n",
    "        try:\n",
    "            vector = glove_model[word]\n",
    "            embedding_glove_mat[i] = vector\n",
    "        except:\n",
    "            continue\n",
    "    glove_embedding_layer = Embedding(input_dim=embedding_glove_mat.shape[0],\n",
    "                          output_dim=embedding_glove_mat.shape[1], \n",
    "                          weights=[embedding_glove_mat],\n",
    "                          input_length=max_length, \n",
    "                          trainable=False)\n",
    "    return glove_embedding_layer\n",
    "\n",
    "model_glove = Sequential()\n",
    "model_glove.add(get_glove_embed_layer(max_length, tokenizer, model_w2v.wv))\n",
    "model_glove.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "model_glove.add(MaxPooling1D(pool_size=2))\n",
    "model_glove.add(Flatten())\n",
    "model_word2vec.add(Dense(11, activation='softmax'))\n",
    "print(model_word2vec.summary())\n",
    "model_word2vec.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_word2vec.fit(X_train, y_train, epochs=10)\n",
    "model_word2vec.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP project",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
